import concurrent.futures
import pathlib
from lmfit.model import propagate_err

import numpy as np
import pandas as pd
import sqlite3
import uproot 

from lmfit import Model, Parameters
import matplotlib as mpl
from matplotlib import pyplot as plt
from matplotlib.colors import LogNorm
from scipy.special import erf
from scipy.ndimage import gaussian_filter1d
from e15190 import PROJECT_DIR
from e15190.utilities import fast_histogram as fh
from e15190.runlog.query import Query


class ShadowBar:
    database_dir = PROJECT_DIR / 'database/neutron_wall/shadow_bar'
    root_files_dir = PROJECT_DIR / 'database/root_files'
    light_GM_range = [5.0, 500.0]  # MeVee
    pos_range = [-120.0, 120.0]  # cm
    psd = [0.5, 2]
    #theta_b=[40,48]
    theta_b=[38,50]
    #theta_f=[32,40]
    theta_f=[29,41]
    nbins1=40
    energy_bin=20
    energy_range=[30,120]
    
    def __init__(self, AB, max_workers=8):
        """Initialize the :py:class:`ShadowBar` class.

        Parameters
        ----------
        AB : str
            Either 'A' or 'B'. To specify neutron wall A or B.
        max_workers : int, default 8
            Maximum number of workers to use for parallelization. The parallelization
            is used to read in data from ROOT files as executors for
            `decompression <https://uproot.readthedocs.io/en/latest/uproot.reading.ReadOnlyFile.html#decompression-executor>`__
            and
            `interpretation <https://uproot.readthedocs.io/en/latest/uproot.reading.ReadOnlyFile.html#interpretation-executor>`__
            in
            `uproot <https://uproot.readthedocs.io/>`__.
        """
        self.AB = AB.upper()
        self.ab = self.AB.lower()
        self.decompression_executor = concurrent.futures.ThreadPoolExecutor(
            max_workers=max_workers)
        self.interpretation_executor = concurrent.futures.ThreadPoolExecutor(
            max_workers=max_workers)
        self.database_dir.mkdir(parents=True, exist_ok=True)

    def _cut_for_root_file_data(self, AB):
        """A simple cut to select valid entries only.

        This is not the final cut. It is only the biggest cut that defines the
        largest subset of data that will be used, i.e. we only throw away
        entries that are not useable or recoverable. Data that are not of our
        *interest* should *not* be thrown away here.
        """
        AB = AB.upper()
        cuts = [
            f'NW{AB}_light_GM > {self.light_GM_range[0]}',
            f'NW{AB}_light_GM < {self.light_GM_range[1]}',
            f'NW{AB}_pos > {self.pos_range[0]}',
            f'NW{AB}_pos < {self.pos_range[1]}',
            f'NW{AB}_psd >{self.psd[0]}',
            f'NW{AB}_psd <{self.psd[1]}',
        ]
        return ' & '.join([f'({c.strip()})' for c in cuts])
    @staticmethod
    def infer_tree_name(uproot_file):
        names=list(set(key.split(';')[0] for key in uproot_file.keys()))
        candidate=None
        n_candidates=0
        for name in names:
            if 'TTree' in str(type(uproot_file[name])):
                n_candidates +=1
                candidate=name
            if n_candidates>1:
                return None
        return candidate 
    def read_run_from_root_file(self, run, tree_name=None, apply_cut=True):
        """Read in single run from ROOT file.

        The ROOT file here refers to the one generated by ``calibrate.cpp``,
        *not* the "Daniele's ROOT file".

        Parameters
        ----------
        run : int
            Run number.
        tree_name : str, default None
            Name of the tree in the ROOT file. If not specified, the function
            will try to automatically determine the tree name. If multiple trees
            are found within the ROOT file, an exception will be raised as the
            function has no way to know which tree to use.
        apply_cut : bool, default True
            If set to `True`, the function will apply the cut specified by
            :py:func:`_cut_for_root_file_data` to the data. Otherwise, the cut
            is not applied.

        Returns
        -------
        df : pd.DataFrame
            Dataframe containing the data for the specified run.
        """
        path = self.root_files_dir / f'run-{run:04d}.root'

        # determine the tree_name
        if tree_name is None:
            with uproot.open(str(path)) as file:
                tree_name=self.infer_tree_name(file)
        
        # load in the data
        
        branches = [
            'MB_multi',
            'VW_multi',
            f'NW{self.AB}_bar',
            f'NW{self.AB}_light_GM',
            f'NW{self.AB}_pos',
            f'NW{self.AB}_theta',
            f'NW{self.AB}_phi',
            f'NW{self.AB}_psd',
            f'NW{self.AB}_distance',
            f'NW{self.AB}_time',
            'FA_time_min',
        ]
        with uproot.open(str(path) + ':' + tree_name) as tree:
            df = tree.arrays(
                branches,
                library='pd',
                decompression_executor=self.decompression_executor,
                interpretation_executor=self.interpretation_executor,
            )

        if apply_cut:
            df = df.query(self._cut_for_root_file_data(self.AB))
        
        # calculate TOF from NW{self.AB}_time - FA_time_min
        df[f'NW{self.AB}_tof'] = df.eval(f'NW{self.AB}_time - FA_time_min')
        # calculate kinetic energy from TOF and NW{self.AB}_distance
        df[f'NW{self.AB}_energy'] = np.power(
            df[f'NW{self.AB}_distance']/df[f'NW{self.AB}_tof'], 2)*0.5*939.5654133*(1.0/9.0)*0.01
        # drop branches that won't be used,
        # e.g. NW{self.AB}_distance, NW{self.AB}_time, FA_time_min
        df.drop([f'NW{self.AB}_distance', f'NW{self.AB}_time',
                 'FA_time_min'], axis=1, inplace=True)

        return df

    def cache_run(self, run, tree_name=None):
        """Read in data from ROOT file and save relevant branches to an SQLite database.

        The data will be grouped according to bar number, because future
        retrieval by this class will most likely analyze only one bar at a time.

        Parameters
        ----------
        run : int
            Run number.
        tree_name : str, default None
            Name of the tree in the ROOT file. If not specified, the function
            will try to automatically determine the tree name. If multiple trees
            are found within the ROOT file, an exception will be raised as the
            function has no way to know which tree to use.
        """
        path = self.database_dir / f'cache/run-{run:04d}.db'
        path.parent.mkdir(parents=True, exist_ok=True)
        df = self.read_run_from_root_file(run, tree_name=tree_name)

        # write cache to SQLite database bar by bar
        columns = [col for col in df.columns if col != f'NW{self.AB}_bar'] # drop bar number
        pathlib.Path(path).unlink(missing_ok=True) # remove pre-existing file, if any
        for bar, subdf in df.groupby(f'NW{self.AB}_bar'):
            subdf.reset_index(drop=True, inplace=True)
            subdf[columns].to_sql(
                f'nw{self.ab}{bar:02d}',
                con=sqlite3.connect(str(path)),
                index=False,
            )
    
    def _read_single_run(self, run, bar, from_cache=True):
        """Read in single run from either cache or ROOT file.

        If no cache is available or ``from_cache`` is set to ``False``, the
        function first prepare a cache for the run by invoking
        :py:func:`cache_run`, then read in the data from the newly created cache
        into a dataframe to be returned. Otherwise, it reads directly from the
        cache and returns the dataframe.

        Notice that the cache file is always generated for one run at a time,
        with multiple dataframes contained in it, each dataframe corresponding
        to one bar. In other words, if you have invoked
        ``_read_single_run(6666, 1)``,
        then a cache file ``cache/run-6666.db`` will be generated, and in it
        there are dataframes for not just bar-01, but also *all* the other bars
        (of course, excluding those that you had chosen to filter out).

        Parameters
        ----------
        run : int
            Run number.
        bar : int
            Bar number.
        from_cache : bool, default True
            If set to `True`, the data will be read from the cache if exists.
            Otherwise, it will refresh the cache by reading again from the ROOT
            file, then read from the newly created cache.

        Returns
        -------
        df : pd.DataFrame
            Dataframe containing the data for the specified run and bar.
        """
        path = self.database_dir / f'cache/run-{run:04d}.db'
        if not from_cache or not path.exists():
            self.cache_run(run)
        
        df = pd.read_sql(
            f'SELECT * FROM nw{self.ab}{bar:02d}',
            con=sqlite3.connect(str(path)),
        )

        # convert all float64 columns into float32 to reduce memory usage
        for col in df.columns:
            if df[col].dtype == np.float64:
                df[col] = df[col].astype(np.float32)

        return df

    def read(self, run, bar, from_cache=True, verbose=False):
        """Read in the data needed to do shadow bar analysis.

        This function reads in the data as a dataframe, and saves it to
        ``self.df``. It also updates ``self.bar`` for future reference.

        The data will be read from the cache files if they exists, otherwise the
        function will read in from the ROOT files (generated by
        ``calibrate.cpp``).

        Branch names that start with ``NW{self.AB}_`` will be dropped because of
        redunancy. For example, ``NWB_psd`` will be reduced into ``psd``.
        However, other prefixes that indicate detectors other than the neutron
        wall will be kept, e.g. ``MB_multi``, ``FA_time_min``, etc.

        Parameters
        ----------
        run : int or list of ints
            The run number(s).
        bar : int
            Bar number.
        from_cache : bool, default True
            If set to `True`, the data will be read from the cache if exists.
            Otherwise, it will refresh the cache by reading again from the ROOT
            file, then read from the newly created cache.
        verbose : bool, default False
            Whether to print out the progress of the read in.

        Example
        -------
        >>> from e15190.neutron_wall.shadow_bar import ShadowBar
        >>> shade = ShadowBar('B') # ShadowBar object for neutron wall B
        >>> shade.read([4083, 4084], 1, verbose=True) # read in run 4083 and 4084, bar-01
        Reading run-4083  (1/2)
        Reading run-4084  (2/2)
        >>> shade.df[['run', 'theta']] # display the columns run and theta for inspection
                run      theta
        0      4083  32.787231
        1      4083  33.294674
        2      4083  35.215828
        3      4083  40.720539
        4      4083  31.086285
        ...     ...        ...
        25253  4084  38.263584
        25254  4084  35.900543
        25255  4084  40.574760
        25256  4084  31.906084
        25257  4084  49.476383
        <BLANKLINE>
        [25258 rows x 2 columns]

        """
        if isinstance(run, int):
            runs = [run]
        else:
            runs = run

        df = None
        for i_run, run in enumerate(runs):
            if verbose:
                print(
                    f'\rReading run-{run:04d}  ({i_run + 1}/{len(runs)})', end='', flush=True)
            df_run = self._read_single_run(run, bar, from_cache=from_cache)
            df_run.insert(0, 'run', run)
            if df is None:
                df = df_run.copy()
            else:
                df = pd.concat([df, df_run], ignore_index=True)
        if verbose:
            print('\r', flush=True)

        self.bar = bar
        self.df = df
        self.df.columns = [name.replace(
            f'NW{self.AB}_', '') for name in self.df.columns]

    def remove_vetowall_coincidences(self):
        self.df = self.df.query('VW_multi == 0')
        self.df.drop('VW_multi', axis=1, inplace=True)

    def gate_on_tof(self):
        self.df = self.df.query('tof>20 & tof<100')
        # self.df.drop('tof', axis=1, inplace=True)

    def preprocessing(self):
        self.gate_on_tof()
        self.remove_vetowall_coincidences()
        

    def make_space_above(ax, topmargin=1):
        """ increase figure size to make topmargin (in inches) space for 
        titles, without changing the axes sizes"""
        fig = ax.flatten()[0].figure
        s = fig.subplotpars
        w, h = fig.get_size_inches()

        figh = h - (1-s.top)*h + topmargin
        fig.subplots_adjust(bottom=s.bottom*h/figh, top=1-topmargin/figh)
        fig.set_figheight(figh)

    def fit_energy_range(self, ene, background_position):
        subdf = self.df[(self.df['energy'] > ene-0.5*self.energy_bin) &
                        (self.df['energy'] < ene+0.5*self.energy_bin)]
        
        if background_position == 'F':
            subdf = subdf[(subdf['theta'] > self.theta_f[0]) & (subdf['theta'] < self.theta_f[1])]
        elif background_position == 'B':
            subdf = subdf[(subdf['theta'] > self.theta_b[0]) & (subdf['theta'] < self.theta_b[1])]
        else:
            print('shadow_bar position is not correct')

        fig, ax = plt.subplots(dpi=120, figsize=(4, 3))
        ax.set_xlabel(r'Lab $\theta$')
        ax.set_ylabel(r'Density')
        if background_position == 'F':
            y, x, _ = ax.hist(subdf['theta'], range=[
                              self.theta_f[0], self.theta_f[1]], bins=self.nbins1, histtype='step')
        elif background_position == 'B':
            y, x, _ = ax.hist(subdf['theta'], range=[
                              self.theta_b[0], self.theta_b[1]], bins=self.nbins1, histtype='step')
        else:
            print('shadow_bar position is not correct')
        x = 0.5 * (x[1:] + x[:-1])
        y_err = np.sqrt(y)

        return x, y, y_err

    def fit_parameters(self, background_position, x, y, y_err):
        def f_kin1(x, k0, k1):
            return k0 + k1 * x

        def f_dip1(x, A, x_L, x_R, s_L, s_R):
            return A*(1.0+0.5*erf(-(x-x_L)/(np.sqrt(2)*s_L))+0.5*erf((x-x_R)/(np.sqrt(2)*s_R)))

        param = Parameters()
        
        if background_position == 'B':
            param.add('k0', value=200)
            param.add('k1', value=1)
            param.add('A', value=50)
            param.add('x_L', value=42, min=40.0, max=44.0)
            param.add('x_R', value=45, min=44.0, max=48.0)
            param.add('s_L', value=0.38, min=0.31, max=0.45)
            param.add('s_R', value=0.38, min=0.31, max=0.45)

        # forward angles
        elif background_position == 'F':
            param.add('k0', value=200)
            param.add('k1', value=1)
            param.add('A', value=50)
            param.add('x_L', value=34, min=30.0, max=35.0)
            param.add('x_R', value=37, min=35.0, max=40.0)
            param.add('s_L', value=0.38, min=0.31, max=0.45)
            param.add('s_R', value=0.38, min=0.31, max=0.45)
        else:
            print('shadow_bar position is not correct')
        gmodel = Model(f_kin1)+Model(f_dip1)
        w = np.divide(
            1,
            y_err,
            where=(y_err != 0),
            out=np.zeros(len(y_err)),
        )
        result = gmodel.fit(y, param, x=x, weights=w, scale_covar=False,calc_covar=True,
                            method='least_squares', nan_policy='propagate')
        
        print(result.fit_report())
        return result
    def fit_scaled_hist(self, background_position, x, y, y_err):
        def f_dipc(x, B, x_L, x_R, s_L, s_R):
            return B+ (1.0-B)*(1.0+0.5*erf(-(x-x_L)/(np.sqrt(2)*s_L))+0.5*erf((x-x_R)/(np.sqrt(2)*s_R)))
        param = Parameters()
        
        if background_position == 'B':
            param.add('B', value=0.5,min=0.01,max=1.0)
            param.add('x_L', value=42, min=40.0, max=44.0)
            param.add('x_R', value=45, min=44.0, max=48.0)
            param.add('s_L', value=0.38, min=0.31, max=0.45)
            param.add('s_R', value=0.38, min=0.31, max=0.45)
            
        # forward angles
        elif background_position == 'F':
            param.add('B', value=0.5,min=0.01,max=1.0)
            param.add('x_L', value=34, min=30.0, max=35.0)
            param.add('x_R', value=37, min=35.0, max=40.0)
            param.add('s_L', value=0.38, min=0.31, max=0.45)
            param.add('s_R', value=0.38, min=0.31, max=0.45)

        else:
            print('shadow_bar position is not correct')
        gmodel = Model(f_dipc)
        w = np.divide(
            1,
            y_err,
            where=(y_err != 0),
            out=np.zeros(len(y_err)),
        )
        result = gmodel.fit(y, param, x=x, weights=w, scale_covar=False,calc_covar=True,
                            method='least_squares', nan_policy='propagate')
        
        print(result.fit_report())
        return result
    def scaled_histogram(self,result,x,y,y_err):
        def f_kin1(x, k0, k1):
            return k0 + k1 * x
        param = Parameters()
        param.add('k0', value=200)
        param.add('k1', value=1)
        index_l,=np.where(x<result.params['x_L'].value)
        index_r,=np.where(x>result.params['x_R'].value)
        print(index_l[-1],index_r[0])
        x2=np.hstack((x[0:index_l[-1]:1],x[index_r[0]:-1:1]))
        y2=np.hstack((y[0:index_l[-1]:1],y[index_r[0]:-1:1]))
        y2_err=np.hstack((y_err[0:index_l[-1]:1],y_err[index_r[0]:-1:1]))
        
        w2= np.divide(
            1,
            y2_err,
            where=(y2_err != 0),
            out=np.zeros(len(y2_err)),
        )
        gmodel1=Model(f_kin1)
        result1=gmodel1.fit(y2,param,x=x2,weights=w2,scale_covar=False,calc_covar=True,method='least_square',nan_policy='propagate')
        return x,y/gmodel1.eval(result1.params,x=x),y_err/gmodel1.eval(result1.params,x=x),result1
    def calculate_background(self, result, x, y):
        # evaluate components
        comps = result.eval_components(x=x)
        covar1 = result.covar

        def y_error(x, dela,delb,delc,covab,covac,covbc,):
            return np.sqrt(dela**2+delb**2+(x*delc)**2+2*covab+2*x*covac+2*x*covbc)
        
        err_y = y_error(
            x, result.params['A'].stderr,result.params['k0'].stderr, result.params['k1'].stderr, covar1[2,0],covar1[2,1],covar1[0, 1])
        
        upper_kin = result.params['A'].value+comps['f_kin1']+err_y
        lower_kin = result.params['A'].value+comps['f_kin1']-err_y

        # eval 1-sigma uncertainty of the best fit
        dely = result.eval_uncertainty(x=x)
        ratio=result.best_fit/(result.params['A'].value+comps['f_kin1'])
       
        ratio_lower=(result.best_fit-dely)/lower_kin
        ratio_upper=(result.best_fit+dely)/upper_kin
        yy=np.where(np.abs(x-0.5*(result.params['x_L'].value+result.params['x_R'].value))<=12.0/self.nbins1)
        bg=ratio[yy[0][0]]
        bg_l=ratio_lower[yy[0][0]]
        bg_u=ratio_upper[yy[0][0]]
        return err_y, bg*1e2, 1e2*0.50*(bg_u-bg_l)

    def _draw_Energy_vs_lightGM(self, ax):
        # two-dimensional histogram
        h = fh.plot_histo2d(
            ax.hist2d,
            self.df['light_GM'], self.df['energy'],
            range=[[0, 100], [0, 120]],
            bins=[1000, 1200],
            cmap=mpl.cm.jet,
            norm=mpl.colors.LogNorm(vmin=1),
        )
        # design

        ax.set_ylabel('Energy (MeV)')
        ax.set_xlabel('G.M. light (MeVee)')
    def _draw_theta_vs_tof(self, ax):
        # two-dimensional histogram
        h = fh.plot_histo2d(
            ax.hist2d,
            self.df['theta'], self.df['tof'],
            range=[[20,60], [0,100]],
            bins=[100, 100],
            cmap=mpl.cm.jet,
            norm=mpl.colors.LogNorm(vmin=1),
        )
        # design

        ax.set_ylabel('tof (ns)')
        ax.set_xlabel('Theta (degree)')

    def _draw_tof_vs_ene(self, ax):
        # two-dimensional histogram
        h = fh.plot_histo2d(
            ax.hist2d,
            self.df['tof'], self.df['energy'],
            range=[[0,150], [0,300]],
            bins=[150, 300],
            cmap=mpl.cm.jet,
            norm=mpl.colors.LogNorm(vmin=1),
        )
        # design
        print(self.df['tof'],self.df['energy'])
        ax.set_ylabel('ene (MeV)')
        ax.set_xlabel('tof (ns)')
    def _draw_counts_vs_theta(self, ene, ax):
        subdf = self.df[(self.df['energy'] > ene-0.5*self.energy_bin) &
                        (self.df['energy'] < ene+0.5*self.energy_bin)]
        # one-dimensional histogram
        h = fh.plot_histo1d(
            ax.hist,
            subdf['theta'],
            range=[20, 60],
            bins=150,
            histtype='step',
        )
        
        ax.set_xlabel('theta (degree)')
        ax.set_ylabel('Counts')
    
    def _draw_counts_vs_psd(self, ene, ax):
        subdf = self.df[(self.df['energy'] > ene-0.5*self.energy_bin) &
                        (self.df['energy'] < ene+0.5*self.energy_bin)]
        # one-dimensional histogram
        h = fh.plot_histo1d(
            ax.hist,
            subdf['psd'],
            range=[-1, 10],
            bins=1000,
            histtype='step',
        )
        
        # design
        # print(len(subdf['psd']))
        ax.set_xlabel('psd')
        ax.set_ylabel('Counts')

    def _draw_phi_vs_theta(self,ax):
        hrange = [[20, 60], [-30, 30]]
        hbins = [1000, 1000]
        h =  fh.plot_histo2d(
            ax.hist2d,
            self.df['theta'],
            self.df['phi'],
            range=hrange,
            bins=hbins,
            cmap=mpl.cm.jet,
        ) 
        plt.colorbar(h[3], ax=ax, pad=-0.02, fraction=0.08, aspect=50.0)
        ax.set_xlabel('\theta (degree)')
        ax.set_ylabel('\phi (degree)')
    def _draw_counts_vs_position(self, ene, ax):
        subdf = self.df[(self.df['energy'] > ene-0.5*self.energy_bin) &
                        (self.df['energy'] < ene+0.5*self.energy_bin)]
        # one-dimensional histogram
        h = fh.plot_histo1d(
            ax.hist,
            subdf['pos'],
            range=[-110, 110],
            bins=220,
            histtype='step',
            
        )
        ax.set_xlabel('position (cm)')
        ax.set_ylabel('Counts')

    def _draw_fitfunction_vs_theta(self, x, y, result, err_y, ax):
        comps = result.eval_components(x=x)
        # upper and lower components of kinematic function
        upper_kin = result.params['A'].value+comps['f_kin1']+err_y
        lower_kin = result.params['A'].value+comps['f_kin1']-err_y
    
        dely = result.eval_uncertainty(x=x)
        ax.errorbar(x, y,yerr=err_y,fmt='o')
        ax.plot(x, result.best_fit)
        ax.plot(x, result.best_fit-dely, 'r--')
        ax.plot(x, result.best_fit+dely, 'm--')
        ax.plot(x, result.params['A'].value+comps['f_kin1'], 'g--')
        ax.fill_between(x, result.best_fit-dely,
                        result.best_fit+dely, color='#888888')
        ax.plot(x, upper_kin, 'y--', label='upper limit')
        ax.plot(x, lower_kin, 'c--', label='lower limit')
        ax.set_ylabel(r'$Y_\mathrm{data}$')
        ax.set_xlabel(r'Lab $\theta$ (deg)')
        ax.legend()
    def _draw_components(self, x, y, err_y, result, ax):
        comps = result.eval_components(x=x)
        ax.plot(x, comps['f_kin1'], 'r--')
        ax.plot(x,comps['f_dip1'],'g--')
        ax.plot(x,result.best_fit,'b--')
        ax.errorbar(x,y,yerr=err_y,fmt='o')
    def _draw_scaled_histo(self, x, y, y_err,result_s, ax):
        ax.errorbar(x, y,
            yerr=y_err,
            fmt='o')
        ax.set_xlabel('Theta (degree)')
        ax.set_ylabel('Spectrum/fit')
        ax.plot(x,result_s.best_fit)
        
    def _draw_histo_fit(self,x,y,y_err,result1,ax):
        def f_kin1(x, k0, k1):
            return k0 + k1 * x
        gmodel=Model(f_kin1)
        ax.errorbar(x, y,
            yerr=y_err,
            fmt='o')
        ax.set_xlabel('Theta (degree)')
        ax.set_ylabel('Counts')
        hires_x = np.linspace(x[0], x[-1], 200)
        ax.plot(hires_x,gmodel.eval(result1.params,x=hires_x),'r--')
    def _draw_background(self, x, y, result, err_y, ax):
        comps = result.eval_components(x=x)
        upper_kin = result.params['A'].value+comps['f_kin1']+err_y
        lower_kin = result.params['A'].value+comps['f_kin1']-err_y
        dely = result.eval_uncertainty(x=x)

        background = np.amin(result.best_fit/(result.params['A'].value+comps['f_kin1']))
        background_upper = np.amin((result.best_fit+dely)/upper_kin)
        background_lower = np.amin((result.best_fit-dely)/lower_kin)
        ax.plot(x, result.best_fit/(result.params['A'].value+comps['f_kin1']), 'r--', label='normalized')
        ax.plot(x, (result.best_fit-dely)/lower_kin,
                'c--', label='lower limit')
        ax.plot(x, (result.best_fit+dely)/upper_kin,
                'y--', label='upper limit')
        ax.set_ylabel(r'$Y_\mathrm{data}(\theta)/Y_\mathrm{kin}(\theta)$')
        ax.set_xlabel(r'Lab $\theta$ (deg)')
        ax.axhline(background, linestyle='dashed', color='red',
                   label='background = %.1f%%' % (1e2*background))
        ax.axhline(background_upper, linestyle='dashed', color='yellow',
                   label='%.1f%%' % (1e2*background_upper))
        ax.axhline(background_lower, linestyle='dashed', color='cyan',
                   label='%.1f%%' % (1e2*background_lower))

    def save_to_gallery_scaled(self, sf, background_position, ene,x,y,y_err,result1, x1, y1, err_y1,result_s, path=None, show_plot=False, save=True):
        filename = '%s+%s_%.02d_MeV_bar_%02d_%s_ene_%.02d_scaled.png' % (
            sf['beam'], sf['target'], sf['beam_energy'], self.bar, background_position, ene)
        
        if path is None:
            path = self.database_dir / 'gallery'/'coupland'/filename
        elif isinstance(path, str):
            path = pathlib.Path(path)
        path.parent.mkdir(parents=True, exist_ok=True)

        fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(
            10, 10), constrained_layout=True)
        fig.suptitle(
            '%s+%s_%.02d_MeV_bar_%02d_%s_ene_%.02d' % (
            sf['beam'], sf['target'], sf['beam_energy'], self.bar, background_position, ene))
        

        rc = (0)
        self._draw_histo_fit(x,y,y_err,result1,ax[rc])
        rc = (1)
        self._draw_scaled_histo(x1,y1,err_y1,result_s,ax[rc])
        plt.draw()
        if save:
            fig.savefig(path, dpi=500, bbox_inches='tight')
        if show_plot:
            plt.show()
        else:
            plt.close()
    def save_to_gallery(self, sf, background_position, ene, x, y, result, err_y, path=None, show_plot=False, save=True):
        """Save a diagnostic plot to the gallery as a PNG file.

        Parameters
            path : str or pathlib.Path, default None
                The path to save the plot. If None, the plot is saved to the
                default database.
            cut : str, default 'light_GM > 3'
                The cut to apply to the data when plotting. All panels in the
                figure will apply this cut, and potentially other cuts, joined
                by logical AND, except for the panel that draws the PPSD as a
                function of light GM.
            show_plot : bool, default False
                If True, the plot will be shown in run time, i.e. the command
                `plt.show()` will be called.
            save : bool, default True
                If `True`, the plot will be saved to the database. `False`
                option is useful when users are using this function to inspect
                the plot without saving.
        """
        
        filename = '%s+%s_%.02d_MeV_bar_%02d_%s_ene_%.02d.png' % (
            sf['beam'], sf['target'], sf['beam_energy'], self.bar, background_position, ene)
        
        if path is None:
            path = self.database_dir / 'gallery'/filename
        elif isinstance(path, str):
            path = pathlib.Path(path)
        path.parent.mkdir(parents=True, exist_ok=True)

        fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(
            10, 10), constrained_layout=True)
        fig.suptitle(
            '%s+%s_%.02d_MeV_bar_%02d_%s_ene_%.02d' % (
            sf['beam'], sf['target'], sf['beam_energy'], self.bar, background_position, ene))

        rc = (0, 0)
        self._draw_counts_vs_theta(ene, ax[rc])
        
        rc = (0, 1)
        self._draw_components(x,y,err_y,result,ax[rc])

        rc = (1, 0)
        self._draw_fitfunction_vs_theta(x, y, result, err_y, ax[rc])

        rc = (1, 1)
        self._draw_background(x, y, result, err_y, ax[rc])
        plt.draw()
        if save:
            fig.savefig(path, dpi=500, bbox_inches='tight')
        if show_plot:
            plt.show()
        else:
            plt.close()

    def fit(self, background_position, path=None):
        self.preprocessing()
        sf = Query.get_run_info(self.df['run'].iloc[0])

        
        filename = '%s+%s_%.02d_MeV_bar_%02d_%s.txt' % (
            sf['beam'], sf['target'], sf['beam_energy'], self.bar, background_position)
        
        if path is None:
            path = self.database_dir / 'gallery'/filename
        elif isinstance(path, str):
            path = pathlib.Path(path)
        path.parent.mkdir(parents=True, exist_ok=True)
 

        filename1 = '%s+%s_%.02d_MeV_bar_%02d_%s.dat' % (
            sf['beam'], sf['target'], sf['beam_energy'], self.bar, background_position)
        filename2 = '%s+%s_%.02d_MeV_bar_%02d_%s.info' % (
            sf['beam'], sf['target'], sf['beam_energy'], self.bar, background_position)

        with open(self.database_dir / 'gallery'/filename1, 'w') as file1, open(self.database_dir / 'gallery'/filename2, 'w') as file2, open(path, 'w') as file:
            file.write('{} {} {} {} \n'.format(
                "bar", "energy", "background", "error"))
            file1.write('{} {} {} {} \n'.format(
                 "bar", "energy", "background", "error"))
            file2.write('{} {} {} {} {} {} {} \n'.format(
                 "bar", "energy", "A", "x0","x1","s0","s1"))
            for ene in np.arange(self.energy_range[0],self.energy_range[1], self.energy_bin):
                x, y, y_err = self.fit_energy_range(ene, background_position)
                #first method
                result = self.fit_parameters(background_position, x, y, y_err)
                err_y, bg, bg_err = self.calculate_background(
                    self.fit_parameters(background_position, x, y, y_err), x, y)
                self.save_to_gallery(sf, background_position, ene, x, y,
                                     result, err_y, path=None, show_plot=False, save=True)
                file1.write('{} {} {} {} \n'.format(self.bar, ene, bg, bg_err))
                #coupland version
                x1,y1,y1_err,result1=self.scaled_histogram(result,x,y,y_err)
                result_s=self.fit_scaled_hist(background_position,x1,y1,y1_err)
                self.save_to_gallery_scaled(sf, background_position, ene,x,y,y_err,result1, x1, y1, y1_err, result_s, path=None, show_plot=False, save=True)
                file.write('{} {} {} {} \n'.format(self.bar, ene, result_s.params['B'].value*100, result_s.params['B'].stderr*100))
                file2.write('{} {} {} {} {} {} {} \n'.format(self.bar, ene, result.params['A'].value, result.params['x_L'].value, result.params['x_R'].value,result.params['x_L'].stderr,result.params['x_R'].stderr))
'Done'
